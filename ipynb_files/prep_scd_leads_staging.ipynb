{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e2b8bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_salesforce import Salesforce\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from datetime import date\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659852b",
   "metadata": {},
   "source": [
    "### Load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f35b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv  \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78142ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SF_USERNAME = os.getenv(\"SF_USERNAME\")\n",
    "SF_PASSWORD_01 = os.getenv(\"SF_PASSWORD_01\")\n",
    "SF_SECURITY_TOKEN = os.getenv(\"SF_SECURITY_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c721e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Salesforce\n",
    "sf = Salesforce(username=SF_USERNAME, password=SF_PASSWORD_01, security_token=SF_SECURITY_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a3fd9",
   "metadata": {},
   "source": [
    "### Load and Cleanse Lead Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ab2050",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_query = sf.query_all(\"\"\"Select \n",
    "Id,\n",
    "CreatedDate, \n",
    "LeadSource, \n",
    "Lead_status__c, \n",
    "ConvertedAccountId, \n",
    "ConvertedOpportunityId, \n",
    "ConvertedDate, \n",
    "CYCLE__c,\n",
    "Intake_Year__c,\n",
    "Online_Source__c,\n",
    "WEB_SOURCE_GRP__c,\n",
    "Market_Segment__c,\n",
    "Level_1__c,\n",
    "Programme_1__c,\n",
    "LEVEL__c,\n",
    "Taylor_s_Faculty__c,\n",
    "Lead_Owner_Role__c,\n",
    "Campus_Preference_1__c                     \n",
    "from \n",
    "Lead\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb251316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_sf_record(record, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in record.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if new_key in ['attributes_type', 'attributes_url']:\n",
    "            continue  # skip these keys\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_sf_record(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Flatten all Salesforce records\n",
    "leads_flattened_record = [flatten_sf_record(rec) for rec in leads_query['records']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e93635",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_table = pd.DataFrame(leads_flattened_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4a52609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize date and time formats for leads table\n",
    "leads_table['date'] = leads_table['CreatedDate'].str.split('T').str[0]  \n",
    "leads_table['time'] = leads_table['CreatedDate'].str.split('T').str[1].str.split('+').str[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ab40933",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_table['CreatedDate'] = pd.to_datetime(leads_table['CreatedDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3b1b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_table['date'] = pd.to_datetime(leads_table['date'], errors='coerce')\n",
    "leads_table['date'] = leads_table['date'].dt.strftime('%d/%m/%Y')\n",
    "leads_table['cdt_leads_table'] = pd.to_datetime(leads_table['date'] + ' ' + leads_table['time'], format='%d/%m/%Y %H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62eb09c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_table = leads_table.rename(columns={'Id': 'leads_id', \n",
    "                              'LeadSource': 'leads_source',\n",
    "                              'CreatedDate' : 'cdt_leads_original',\n",
    "                              'Lead_status__c': 'leads_status',\n",
    "                              'ConvertedAccountId': 'account_id',\n",
    "                              'ConvertedOpportunityId': 'opp_id',\n",
    "                              'CYCLE__c': 'leads_cycle',\n",
    "                              'Intake_Year__c': 'leads_intake_year',\n",
    "                              'Online_Source__c':'leads_online_source',\n",
    "                              'WEB_SOURCE_GRP__c': 'leads_web_source_grp',\n",
    "                              'Market_Segment__c': 'leads_market_segment', \n",
    "                              'Level_1__c':'leads_level_1',\n",
    "                              'Programme_1__c':'leads_programme_preference',\n",
    "                              'LEVEL__c':'leads_level',\n",
    "                              'Taylor_s_Faculty__c':'leads_taylor_faculty',\n",
    "                              'Lead_Owner_Role__c':'leads_owner_role',\n",
    "                              'Campus_Preference_1__c':'leads_campus_preference'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b6fab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_final=leads_table[['leads_id','leads_source','leads_status','account_id','opp_id','leads_cycle','leads_intake_year','cdt_leads_original',\n",
    "                         'leads_online_source','leads_web_source_grp','leads_market_segment','leads_level_1','leads_programme_preference','leads_level','leads_taylor_faculty',\n",
    "                         'leads_owner_role','leads_campus_preference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abf0f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def standardize_campus_simple(campus):\n",
    "    if pd.isna(campus) or not str(campus).strip():\n",
    "        return \"Not specified\"\n",
    "    \n",
    "    campus_str = str(campus).strip()\n",
    "    \n",
    "    # Check for TU patterns first\n",
    "    tu_patterns = [\n",
    "        r'taylor\\'?s universit',  # Taylor's University variations\n",
    "        r'\\bTU\\b',               # Standalone TU\n",
    "        r'^TU[^-]',              # TU at start\n",
    "        r'universit.*TU',        # University followed by TU\n",
    "        r'TU.*universit'         # TU followed by University\n",
    "    ]\n",
    "    \n",
    "    for pattern in tu_patterns:\n",
    "        if re.search(pattern, campus_str, re.IGNORECASE):\n",
    "            return \"TU\"\n",
    "    \n",
    "    # Check for TC patterns (including TCSH and TCSJ)\n",
    "    tc_patterns = [\n",
    "        r'taylor\\'?s college',   # Taylor's College variations\n",
    "        r'\\bTC(S[HJ])?\\b',       # TC, TCSH, or TCSJ\n",
    "        r'^TC[^-]',              # TC at start\n",
    "        r'college.*TC',          # College followed by TC\n",
    "        r'TC.*college',          # TC followed by College\n",
    "        r'sri hartamas',         # Sri Hartamas (TCSH)\n",
    "        r'subang jaya',          # Subang Jaya (TCSJ)\n",
    "        r'hartamas',             # Hartamas\n",
    "        r'subang'                # Subang\n",
    "    ]\n",
    "    \n",
    "    for pattern in tc_patterns:\n",
    "        if re.search(pattern, campus_str, re.IGNORECASE):\n",
    "            return \"TC\"\n",
    "    \n",
    "    # Handle special cases\n",
    "    if re.search(r'not specified|unspecified|not set', campus_str, re.IGNORECASE):\n",
    "        return \"Not specified\"\n",
    "    \n",
    "    if re.search(r'unknown|unknow', campus_str, re.IGNORECASE):\n",
    "        return \"Unknown Campus\"\n",
    "    \n",
    "    # Return original if no patterns matched\n",
    "    return campus_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10f82ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\112363\\AppData\\Local\\Temp\\ipykernel_7584\\752951272.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  leads_final['leads_campus_preference'] = leads_final['leads_campus_preference'].apply(standardize_campus_simple)\n"
     ]
    }
   ],
   "source": [
    "# Apply the regex standardization\n",
    "leads_final['leads_campus_preference'] = leads_final['leads_campus_preference'].apply(standardize_campus_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1e44842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "current_year = datetime.now().year\n",
    "min_year = 2000\n",
    "max_year = current_year + 5  # 5 years in future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f5d9ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_year(value):\n",
    "    try:\n",
    "        # Try to convert to numeric\n",
    "        year = pd.to_numeric(value, errors='coerce')\n",
    "        \n",
    "        # Check if it's within our valid range\n",
    "        if not pd.isna(year) and (min_year <= year <= max_year):\n",
    "            return int(year)\n",
    "        return None  # Will become NaN in pandas\n",
    "    \n",
    "    except:\n",
    "        return None  # Will become NaN for any non-convertible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e36dae30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\112363\\AppData\\Local\\Temp\\ipykernel_7584\\2457509791.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  leads_final['clean_intake_year'] = leads_final['leads_intake_year'].apply(clean_year)\n"
     ]
    }
   ],
   "source": [
    "# Apply cleaning and filtering\n",
    "leads_final['clean_intake_year'] = leads_final['leads_intake_year'].apply(clean_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caf636a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_final = leads_final.drop(['leads_intake_year'], axis=1)\n",
    "leads_final = leads_final.rename(columns={'clean_intake_year': 'leads_intake_year'})\n",
    "leads_final['leads_intake_year'] = pd.to_datetime(leads_final['leads_intake_year'], format='%Y')\n",
    "leads_final['leads_intake_year'] = leads_final['leads_intake_year'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00568511",
   "metadata": {},
   "source": [
    "### Load and Cleanse Lead History Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72cf8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_history = sf.query_all(\"\"\"SELECT Id, LeadId, OldValue, NewValue ,CreatedDate\n",
    "FROM LeadHistory\n",
    "WHERE field = 'Status'\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2b7edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_sf_record(record, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in record.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if new_key in ['attributes_type', 'attributes_url']:\n",
    "            continue  # skip these keys\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_sf_record(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Flatten all Salesforce records\n",
    "leads_history_flattened_records = [flatten_sf_record(rec) for rec in leads_history['records']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4353c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_history_table = pd.DataFrame(leads_history_flattened_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18d52315",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_history_table['date'] = lead_history_table['CreatedDate'].str.split('T').str[0]  \n",
    "lead_history_table['time'] = lead_history_table['CreatedDate'].str.split('T').str[1].str.split('+').str[0]  \n",
    "lead_history_table['CreatedDate'] = pd.to_datetime(lead_history_table['CreatedDate'])\n",
    "lead_history_table['date'] = pd.to_datetime(lead_history_table['date'], errors='coerce')\n",
    "lead_history_table['date'] = lead_history_table['date'].dt.strftime('%d/%m/%Y')\n",
    "lead_history_table['cdt_leads_table'] = pd.to_datetime(lead_history_table['date'] + ' ' + lead_history_table['time'], format='%d/%m/%Y %H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0ee9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_history_table = lead_history_table.rename(columns={\n",
    "                                            'Id' : 'leads_history_id',\n",
    "                                            'LeadId': 'leads_id', \n",
    "                                            'OldValue': 'old_value',\n",
    "                                            'NewValue': 'new_value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeb0af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_history_table = lead_history_table.rename(columns={'CreatedDate': 'created_date'})\n",
    "lead_history_table = lead_history_table.rename(columns={'created_date': 'cdt_leads_original'})\n",
    "lead_history_table = lead_history_table.drop(['date','time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e77af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_history_table_v2 = lead_history_table[['leads_id','old_value','new_value','cdt_leads_original']]\n",
    "leads_history_table_v2 = lead_history_table.rename(columns={'cdt_leads_original': 'cdt_leadshistory_original'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "266b6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_final_v2 = leads_final[['leads_id','leads_source','leads_status','account_id','opp_id','cdt_leads_original','leads_cycle','leads_intake_year',\n",
    "                              'leads_online_source','leads_web_source_grp','leads_market_segment','leads_level_1','leads_programme_preference','leads_level',\n",
    "                              'leads_taylor_faculty','leads_owner_role','leads_campus_preference']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae725f",
   "metadata": {},
   "source": [
    "# Merge leads history with leads table on leads_id to find id that do not exist in leads history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e367ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lh_ld_join = leads_history_table_v2.merge(leads_final_v2, how='left', on='leads_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb76a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_in_final = set(leads_final_v2['leads_id'])\n",
    "leads_in_history = set(leads_history_table_v2['leads_id'])\n",
    "missing_in_history = list(leads_in_final - leads_in_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc3253fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_records = leads_final_v2[leads_final_v2['leads_id'].isin(missing_in_history)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51073cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_records = missing_records.rename(columns={'cdt_leads_original': 'validfrom'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d81608f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "missing_records['validto'] = pd.NaT\n",
    "missing_records['is_current'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608db775",
   "metadata": {},
   "source": [
    "### SCD Records for leads table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26ae1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "scd_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "528404dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for leads_id, group in lh_ld_join.groupby('leads_id'):\n",
    "    group = group.reset_index(drop=True)\n",
    "    \n",
    "    # Handle the first record for each lead\n",
    "    first_row = group.iloc[0]\n",
    "    \n",
    "    # Create a record for the initial OldValue\n",
    "    initial_old_value = {\n",
    "        'leads_id': leads_id,\n",
    "        'leads_status': first_row['old_value'],\n",
    "        'validfrom': first_row['cdt_leads_original'], # The start date is the createddate in leads table\n",
    "        'validto': first_row['cdt_leadshistory_original'],\n",
    "        'leads_source' : first_row['leads_source'],\n",
    "        'leads_cycle' : first_row['leads_cycle'],\n",
    "        'leads_intake_year' : first_row['leads_intake_year'],\n",
    "        'leads_online_source' : first_row['leads_online_source'],\n",
    "        'leads_web_source_grp' : first_row['leads_web_source_grp'],\n",
    "        'leads_market_segment' : first_row['leads_market_segment'],\n",
    "        'leads_level_1' : first_row['leads_level_1'],\n",
    "        'leads_programme_1' : first_row['leads_programme_preference'],\n",
    "        'leads_level' : first_row['leads_level'],\n",
    "        'leads_taylor_faculty' : first_row['leads_taylor_faculty'],\n",
    "        'leads_owner_role' : first_row['leads_owner_role'],\n",
    "        'leads_campus_preference' : first_row['leads_campus_preference'],\n",
    "        'is_current': False\n",
    "    }\n",
    "    scd_records.append(initial_old_value)\n",
    "    \n",
    "    # Now, iterate through the records to capture the changes\n",
    "    for i in range(len(group)):\n",
    "        row = group.iloc[i]\n",
    "        validfrom = row['cdt_leadshistory_original']\n",
    "        \n",
    "        # Determine the end date for the current status.\n",
    "        # It's the start date of the next record, or None for the final record.\n",
    "        if i + 1 < len(group):\n",
    "            validto = group.iloc[i+1]['cdt_leadshistory_original']\n",
    "        else:\n",
    "            validto = None\n",
    "        \n",
    "        is_current = (i == len(group) - 1)\n",
    "        \n",
    "        # Create the record for the new status\n",
    "        new_status_record = {\n",
    "            'leads_id': leads_id,\n",
    "            'leads_status': row['new_value'],\n",
    "            'validfrom': validfrom,\n",
    "            'validto': validto,\n",
    "            'leads_source' : row['leads_source'],\n",
    "            'leads_cycle' : row['leads_cycle'],\n",
    "            'leads_intake_year' : row['leads_intake_year'],\n",
    "            'leads_online_source' : row['leads_online_source'],\n",
    "            'leads_web_source_grp' : row['leads_web_source_grp'],\n",
    "            'leads_market_segment' : row['leads_market_segment'],\n",
    "            'leads_level_1' : row['leads_level_1'],\n",
    "            'leads_programme_1' : row['leads_programme_preference'],\n",
    "            'leads_level' : row['leads_level'],\n",
    "            'leads_taylor_faculty' : row['leads_taylor_faculty'],\n",
    "            'leads_owner_role' : first_row['leads_owner_role'],\n",
    "            'leads_campus_preference' : first_row['leads_campus_preference'],   \n",
    "            'is_current': is_current\n",
    "        }\n",
    "        scd_records.append(new_status_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e5c7a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "scd_df = pd.DataFrame(scd_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7f657",
   "metadata": {},
   "source": [
    "### Appending missing records to the scd table to combine the new data generated in leads table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfa6b0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scd_df_final = pd.concat([scd_df, missing_records], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98a7d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scd_df_final = scd_df_final.drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "021de2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scd_df_final['validto'] = scd_df_final['validto'].replace({pd.NaT: pd.Timestamp('9999-12-31 00:00:00+00:00')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b06fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scd_df_final['validfromyear'] = pd.to_datetime(scd_df_final['validfrom']).dt.year\n",
    "scd_df_final['validfrommonth'] = pd.to_datetime(scd_df_final['validfrom']).dt.month\n",
    "scd_df_final['validfromday'] = pd.to_datetime(scd_df_final['validfrom']).dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69e42c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.parse import quote\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    " \n",
    "def marcommdb_connection():\n",
    "    # Load environment variables\n",
    "    load_dotenv(override=True) \n",
    " \n",
    "    # Get credentials from environment variables\n",
    "    username = os.getenv(\"PG_USERNAME\")\n",
    "    password = os.getenv(\"PG_PASSWORD\")\n",
    "    host = os.getenv(\"PG_HOST\")\n",
    "    port = os.getenv(\"PG_PORT\")\n",
    "    database = os.getenv(\"PG_DATABASE_EXPORT\")\n",
    " \n",
    "    # Ensure all credentials are available\n",
    "    if not all([username, password, host, port, database]):\n",
    "        raise ValueError(\"Missing one or more PostgreSQL environment variables!\")\n",
    " \n",
    "    # Encode password to handle special characters\n",
    "    encoded_password = quote(password, safe=\"\") if password else \"\"\n",
    " \n",
    "    # Construct PostgreSQL connection string\n",
    "    DATABASE_URL = f\"postgresql+psycopg2://{username}:{encoded_password}@{host}:{port}/{database}\"\n",
    " \n",
    "    # Create and return SQLAlchemy engine\n",
    "    return create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbb419ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine= marcommdb_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1aff2c",
   "metadata": {},
   "source": [
    "### Export to Marcomm DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf895f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scd_df_final.to_sql(\n",
    "    'leads_history_staging',\n",
    "    engine,\n",
    "    schema='staging',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
