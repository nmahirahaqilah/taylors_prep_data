{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92f417b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_salesforce import Salesforce\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from datetime import date\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8f1410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "username = os.getenv(\"PG_USERNAME\")\n",
    "password = os.getenv(\"PG_PASSWORD\")\n",
    "host = os.getenv(\"PG_HOST\")\n",
    "port = os.getenv(\"PG_PORT\")\n",
    "database = os.getenv(\"PG_DATABASE_EXPORT\")\n",
    "\n",
    "# URL-encode the password\n",
    "encoded_password = quote_plus(password)\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{username}:{encoded_password}@{host}:{port}/{database}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e202fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"\n",
    "SELECT\n",
    "*\n",
    "FROM staging.leads_opp_staging\n",
    "where programme_name = 'Unknown'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "953e468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_df = pd.read_sql(query1, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41245e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433194, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72a8c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load files ---\n",
    "first_tier  = pd.read_excel(r\"C:/Users/112363/OneDrive - Taylor's Education Group/DWH_WIP/programme_code_mapping.xlsx\", sheet_name=\"Tier1\")\n",
    "second_tier = pd.read_excel(r\"C:/Users/112363/OneDrive - Taylor's Education Group/DWH_WIP/programme_code_mapping.xlsx\", sheet_name=\"Tier2\")\n",
    "third_tier  = pd.read_excel(r\"C:/Users/112363/OneDrive - Taylor's Education Group/DWH_WIP/programme_code_mapping.xlsx\", sheet_name=\"Tier3\")\n",
    "fourth_tier = pd.read_excel(r\"C:/Users/112363/OneDrive - Taylor's Education Group/DWH_WIP/programme_code_mapping.xlsx\", sheet_name=\"Tier4\")\n",
    "odl_tier    = pd.read_excel(r\"C:/Users/112363/OneDrive - Taylor's Education Group/DWH_WIP/programme_code_mapping.xlsx\", sheet_name=\"ODL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "456cc615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22e35b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "programme_name                                                                   \n",
       "Unknown                                                                              332106\n",
       "General Certificate of Education - Advanced Level (GCE A Level)                       44892\n",
       "Master of Teaching and Learning (ODL)                                                 33395\n",
       "Foundation in Computing                                                               13464\n",
       "Advanced Diploma In Patisserie and Gastronomic Cuisine                                 5226\n",
       "Bachelor of Accounting and Finance (Honours)                                           2635\n",
       "Bachelor of Mass Communication (Honours) in Public Relations and Event Management       895\n",
       "Bachelor of Electrical and Electronic Engineering with Honours                          412\n",
       "Bachelor of Actuarial Studies (Honours)                                                 119\n",
       "Bachelor of Mass Communication (Honours) in Advertising and Brand Management             50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from functools import lru_cache\n",
    "\n",
    "# -------------------------\n",
    "# 0) Normalize columns (vectorized)\n",
    "# -------------------------\n",
    "def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df\n",
    "\n",
    "first_tier  = normalize_cols(first_tier)\n",
    "second_tier = normalize_cols(second_tier)\n",
    "third_tier  = normalize_cols(third_tier)\n",
    "fourth_tier = normalize_cols(fourth_tier)\n",
    "odl_tier    = normalize_cols(odl_tier)\n",
    "data_df     = normalize_cols(unknown_df)\n",
    "\n",
    "# Ensure intake_year column exists & numeric\n",
    "if \"intake_year\" not in data_df.columns:\n",
    "    for alt in [\"Intake Year\", \"intakeyear\", \"IntakeYear\"]:\n",
    "        if alt in data_df.columns:\n",
    "            data_df = data_df.rename(columns={alt: \"intake_year\"})\n",
    "            break\n",
    "if \"intake_year\" in data_df.columns:\n",
    "    data_df[\"intake_year\"] = pd.to_numeric(data_df[\"intake_year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Lowercase helpers for consistent text compares\n",
    "for col in [\"programme1\", \"level1\", \"vertical1\"]:\n",
    "    if col in data_df.columns:\n",
    "        data_df[col + \"__lc\"] = data_df[col].astype(str).str.lower()\n",
    "        \n",
    "# -------------------------\n",
    "# 1) Year range parser (vectorized)\n",
    "# -------------------------\n",
    "def prepare_rule_tier(df_rules: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df_rules.copy()\n",
    "    if \"Intake Year\" in df.columns:\n",
    "        # Accept \"YYYY\" or \"YYYY-YYYY\"\n",
    "        yr = df[\"Intake Year\"].astype(str).str.strip()\n",
    "        span = yr.str.extract(r\"^\\s*(\\d{4})\\s*-\\s*(\\d{4})\\s*$\")\n",
    "        single = yr.str.extract(r\"^\\s*(\\d{4})\\s*$\")\n",
    "        df[\"start_year\"] = pd.to_numeric(span[0].fillna(single[0]), errors=\"coerce\")\n",
    "        df[\"end_year\"]   = pd.to_numeric(span[1].fillna(single[0]), errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "first_tier  = prepare_rule_tier(first_tier)\n",
    "second_tier = prepare_rule_tier(second_tier)\n",
    "third_tier  = prepare_rule_tier(third_tier)\n",
    "fourth_tier = prepare_rule_tier(fourth_tier)\n",
    "odl_tier    = prepare_rule_tier(odl_tier)\n",
    "\n",
    "# -------------------------\n",
    "# 2) Wildmatch helpers (cached + vectorized)\n",
    "# -------------------------\n",
    "@lru_cache(maxsize=2048)\n",
    "def _compile_wildcard(pattern: str):\n",
    "    esc = re.escape(str(pattern))\n",
    "    esc = esc.replace(r\"\\*\", \".*\").replace(r\"\\?\", \".\")\n",
    "    return re.compile(rf\"^{esc}$\", flags=re.IGNORECASE)\n",
    "\n",
    "def series_wildmatch(series: pd.Series, patterns):\n",
    "    \"\"\"Vectorized 'wildmatch' across a Series for many patterns.\"\"\"\n",
    "    s = series.fillna(\"\").astype(str)\n",
    "    # Fast path: combine patterns into one big alternation regex if possible\n",
    "    # (still uses per-pattern compile cache once)\n",
    "    masks = []\n",
    "    for p in patterns:\n",
    "        masks.append(s.str.match(_compile_wildcard(p)))\n",
    "    if not masks:\n",
    "        return pd.Series(False, index=series.index)\n",
    "    # OR all masks\n",
    "    out = masks[0]\n",
    "    for m in masks[1:]:\n",
    "        out = out | m\n",
    "    return out\n",
    "\n",
    "# -------------------------\n",
    "# 3) Compile each Programme_Code_Rule into a vectorized mask\n",
    "# -------------------------\n",
    "_wild_re = re.compile(\n",
    "    r\"wildmatch\\s*\\(\\s*([A-Za-z_][A-Za-z0-9_]*)\\s*,\\s*([^)]+?)\\s*\\)\",\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "def _parse_patterns(arg_text: str):\n",
    "    # split comma-separated quoted patterns: 'a','b','c'\n",
    "    # tolerate quotes \" or '\n",
    "    parts = re.findall(r\"\"\"(['\"])(.*?)\\1\"\"\", arg_text)\n",
    "    return [p[1] for p in parts] if parts else []\n",
    "\n",
    "def compile_rule_to_mask(rule_str: str, df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Turn a Qlik-like rule string into a vectorized boolean pandas Series.\n",
    "    Supports:\n",
    "      - wildmatch(col, 'pat1','pat2',...)\n",
    "      - AND/OR/NOT (case-insensitive)\n",
    "      - simple numeric/string comparisons against df columns (e.g. intake_year < 2022)\n",
    "    \"\"\"\n",
    "    expr = str(rule_str).strip()\n",
    "    expr = re.sub(r\"\\bAND\\b\", \"&\", expr, flags=re.IGNORECASE)\n",
    "    expr = re.sub(r\"\\bOR\\b\",  \"|\", expr, flags=re.IGNORECASE)\n",
    "    expr = re.sub(r\"\\bNOT\\b\", \"~\", expr, flags=re.IGNORECASE)\n",
    "\n",
    "    masks = {}\n",
    "    repls = []\n",
    "    # Replace each wildmatch(...) with a placeholder variable name\n",
    "    for i, m in enumerate(_wild_re.finditer(expr)):\n",
    "        col = m.group(1)\n",
    "        args = m.group(2)\n",
    "        pats = _parse_patterns(args)\n",
    "        placeholder = f\"_WMASK_{i}_\"\n",
    "        repls.append((m.span(), placeholder, col, pats))\n",
    "\n",
    "    # Build the final expression by splicing placeholders in reverse order\n",
    "    expr_list = list(expr)\n",
    "    for (start, end), placeholder, col, pats in reversed(repls):\n",
    "        expr_list[start:end] = placeholder\n",
    "        # choose lowercased column if present to be consistent\n",
    "        col_use = col + \"__lc\" if (col + \"__lc\") in df.columns else col\n",
    "        masks[placeholder] = series_wildmatch(df[col_use] if col_use in df.columns else pd.Series(\"\", index=df.index), pats)\n",
    "\n",
    "    final_expr = \"\".join(expr_list)\n",
    "\n",
    "    # Create evaluation context: df columns as variables\n",
    "    ctx = {c: df[c] for c in df.columns}\n",
    "    ctx.update(masks)\n",
    "\n",
    "    # Evaluate safely with pandas eval (python engine for Series ops)\n",
    "    try:\n",
    "        mask = pd.eval(final_expr, engine=\"python\", local_dict=ctx)\n",
    "        # Ensure boolean Series\n",
    "        mask = mask.astype(bool)\n",
    "    except Exception:\n",
    "        # Fallback: nothing matches if expression fails\n",
    "        mask = pd.Series(False, index=df.index)\n",
    "    return mask\n",
    "\n",
    "# -------------------------\n",
    "# 4) Rule-tier evaluator (vectorized per rule, not per row)\n",
    "# -------------------------\n",
    "def apply_rule_tier(df_rules: pd.DataFrame, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Returns two Series: name_out, code_out from a rule-based tier.\n",
    "    First match wins (by row order in df_rules).\n",
    "    \"\"\"\n",
    "    name_out = pd.Series(pd.NA, index=df.index, dtype=\"object\")\n",
    "    code_out = pd.Series(pd.NA, index=df.index, dtype=\"object\")\n",
    "\n",
    "    if not {\"Programme_Code_Rule\", \"Programme Name\"}.issubset(df_rules.columns):\n",
    "        return name_out, code_out\n",
    "\n",
    "    # Pre-extract code column existence\n",
    "    has_code = \"Programme Code\" in df_rules.columns\n",
    "\n",
    "    for _, r in df_rules.iterrows():\n",
    "        mask = pd.Series(True, index=df.index)\n",
    "\n",
    "        # Year filter\n",
    "        if \"start_year\" in r and pd.notna(r[\"start_year\"]) and \"intake_year\" in df.columns:\n",
    "            mask &= df[\"intake_year\"].between(int(r[\"start_year\"]), int(r[\"end_year\"]))\n",
    "\n",
    "        # Rule expression\n",
    "        rule = r[\"Programme_Code_Rule\"]\n",
    "        mask &= compile_rule_to_mask(rule, df)\n",
    "\n",
    "        # Only fill where not already set\n",
    "        to_fill = mask & name_out.isna()\n",
    "        if to_fill.any():\n",
    "            name_out.loc[to_fill] = r[\"Programme Name\"]\n",
    "            if has_code and pd.notna(r.get(\"Programme Code\", pd.NA)):\n",
    "                code_out.loc[to_fill] = str(r[\"Programme Code\"])\n",
    "\n",
    "        # Early exit if everything is filled\n",
    "        if name_out.notna().all():\n",
    "            break\n",
    "\n",
    "    return name_out, code_out\n",
    "\n",
    "# -------------------------\n",
    "# 5) Mapping-tier evaluator (vectorized via maps/merges)\n",
    "# -------------------------\n",
    "def apply_mapping_tier(df_map: pd.DataFrame, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Priority:\n",
    "      1) (programme1, level1, vertical1)\n",
    "      2) (programme1, level1)\n",
    "      3) (programme1, vertical1)\n",
    "      4) (programme1)\n",
    "    Returns name_out, code_out Series.\n",
    "    \"\"\"\n",
    "    name_out = pd.Series(pd.NA, index=df.index, dtype=\"object\")\n",
    "    code_out = pd.Series(pd.NA, index=df.index, dtype=\"object\")\n",
    "    if \"Programme Name\" not in df_map.columns:\n",
    "        return name_out, code_out\n",
    "\n",
    "    # Normalize lookup columns to lowercase\n",
    "    m = df_map.copy()\n",
    "    for k in [\"programme1\", \"level1\", \"vertical1\"]:\n",
    "        if k in m.columns:\n",
    "            m[k + \"__lc\"] = m[k].astype(str).str.lower()\n",
    "\n",
    "    # Build keyed dicts and fill in priority order with .map (fast)\n",
    "    def _map_by_keys(keys):\n",
    "        # Only proceed if all keys exist in both df and map\n",
    "        if not all((k + \"__lc\") in df.columns for k in keys):\n",
    "            return\n",
    "        if not all((k + \"__lc\") in m.columns for k in keys):\n",
    "            return\n",
    "        key_series = df[[k + \"__lc\" for k in keys]].astype(str).agg(\"|\".join, axis=1)\n",
    "        key_map = m.drop_duplicates(subset=[k + \"__lc\" for k in keys]).copy()\n",
    "        key_map[\"__k__\"] = key_map[[k + \"__lc\" for k in keys]].astype(str).agg(\"|\".join, axis=1)\n",
    "        name_dict = dict(zip(key_map[\"__k__\"], key_map[\"Programme Name\"]))\n",
    "        code_dict = dict(zip(key_map[\"__k__\"], key_map[\"Programme Code\"])) if \"Programme Code\" in key_map.columns else {}\n",
    "\n",
    "        fill_mask = name_out.isna()\n",
    "        if fill_mask.any():\n",
    "            ks = key_series.where(fill_mask)\n",
    "            name_out.update(ks.map(name_dict))\n",
    "            if code_dict:\n",
    "                code_out.update(ks.map(code_dict))\n",
    "\n",
    "    _map_by_keys([\"programme1\", \"level1\", \"vertical1\"])\n",
    "    _map_by_keys([\"programme1\", \"level1\"])\n",
    "    _map_by_keys([\"programme1\", \"vertical1\"])\n",
    "    _map_by_keys([\"programme1\"])\n",
    "\n",
    "    return name_out, code_out\n",
    "\n",
    "# -------------------------\n",
    "# 6) Apply tiers in priority order (fully vectorized)\n",
    "# -------------------------\n",
    "TIERS = [first_tier, second_tier, third_tier, fourth_tier, odl_tier]\n",
    "\n",
    "out_name = pd.Series(pd.NA, index=data_df.index, dtype=\"object\")\n",
    "out_code = pd.Series(pd.NA, index=data_df.index, dtype=\"object\")\n",
    "\n",
    "for tier_df in TIERS:\n",
    "    if \"Programme_Code_Rule\" in tier_df.columns:\n",
    "        n, c = apply_rule_tier(tier_df, data_df)\n",
    "    else:\n",
    "        n, c = apply_mapping_tier(tier_df, data_df)\n",
    "\n",
    "    fill = out_name.isna() & n.notna()\n",
    "    if fill.any():\n",
    "        out_name.loc[fill] = n.loc[fill]\n",
    "        out_code.loc[fill] = c.loc[fill]\n",
    "\n",
    "    # Early exit if all rows resolved\n",
    "    if out_name.notna().all():\n",
    "        break\n",
    "\n",
    "# Fallbacks\n",
    "out_name = out_name.fillna(\"Unknown\")\n",
    "out_code = out_code.astype(\"object\")\n",
    "\n",
    "data_df[\"programme_name\"] = out_name\n",
    "data_df[\"programme_code\"] = out_code\n",
    "\n",
    "\n",
    "data_df[[\"programme_name\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baf88ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.drop(['programme1__lc', 'level1__lc','vertical1__lc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a463606",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"\"\"\n",
    "SELECT\n",
    "*\n",
    "FROM staging.leads_opp_staging\n",
    "where programme_name != 'Unknown'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ca057b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_df = pd.read_sql(query2, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e1985a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([unknown_df, known_df], axis=0, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8d4bd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5396042, 30)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5f77abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.dispose()\n",
    "import os\n",
    "from urllib.parse import quote\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    " \n",
    "def marcommdb_connection():\n",
    "    # Load environment variables\n",
    "    load_dotenv(override=True) \n",
    " \n",
    "    # Get credentials from environment variables\n",
    "    username = os.getenv(\"PG_USERNAME\")\n",
    "    password = os.getenv(\"PG_PASSWORD\")\n",
    "    host = os.getenv(\"PG_HOST\")\n",
    "    port = os.getenv(\"PG_PORT\")\n",
    "    database = os.getenv(\"PG_DATABASE_EXPORT\")\n",
    " \n",
    "    # Ensure all credentials are available\n",
    "    if not all([username, password, host, port, database]):\n",
    "        raise ValueError(\"Missing one or more PostgreSQL environment variables!\")\n",
    " \n",
    "    # Encode password to handle special characters\n",
    "    encoded_password = quote(password, safe=\"\") if password else \"\"\n",
    " \n",
    "    # Construct PostgreSQL connection string\n",
    "    DATABASE_URL = f\"postgresql+psycopg2://{username}:{encoded_password}@{host}:{port}/{database}\"\n",
    " \n",
    "    # Create and return SQLAlchemy engine\n",
    "    return create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1eb337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine= marcommdb_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6c0206c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy.types import Integer\n",
    "\n",
    "combined_df.to_sql(\n",
    "    'leads_opp_staging',\n",
    "    engine,\n",
    "    schema='staging',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
